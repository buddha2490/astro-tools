
R version 4.4.3 (2025-02-28 ucrt) -- "Trophy Case"
Copyright (C) 2025 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(dplyr)

Attaching package: 'dplyr'

The following objects are masked from 'package:stats':

    filter, lag

The following objects are masked from 'package:base':

    intersect, setdiff, setequal, union

> library(magrittr)
> 
> setwd("C:/users/bcart/Astronomy/astro-tools/postprocessing")
> 
> 
> 
> # Functions ---------------------------------------------------------------
> 
> # go get my darks
> getDarks <- function(temp = temp, gain = gain, duration = duration, copyto = sessions) {
+   
+   biasfile <- glue::glue("{darks}/{temp}/Gain{gain}/masterBias_gain{gain}.xisf") %>% normalizePath()
+   
+   darkfile <- glue::glue("{darks}/{temp}/Gain{gain}/masterDark_{duration}s.xisf") %>% normalizePath()
+   
+   biasCopyto <- glue::glue("{copyto}/flats") %>% normalizePath()
+   
+   file.copy(biasfile, biasCopyto)
+   
+   file.copy(darkfile, copyto)
+   
+ }
> 
> processObjects <- function(myObject) {
+   
+ 
+   # I only want to process the last night
+   # The most recent imaging session will be labeled with last nights' date
+   sessions <- data.frame(object = basename(dirname(myObject)))  %>%
+     mutate(folder = (myObject)) %>%
+     mutate(session = basename(myObject)) %>%
+     mutate(dates = stringr::str_replace(session, paste0(object, "_"), "")) 
+ 
+   date <- sessions$dates %>%  as.character()
+   
+   objectName <- sessions$object %>% as.character() 
+   
+   path <- sessions$folder[1]
+   
+   # Get the image metadata
+   # This metadata file does not include calibration subs
+   metadata <- file.path(path, "ImageMetaData.csv") %>%
+     readr::read_csv()
+   
+ 
+   # create some directories
+   objectFlats <- glue::glue(path, "/flats"); dir.create(objectFlats, showWarnings = FALSE)
+   objectFits <- glue::glue(path, "/checkFits"); dir.create(objectFits, showWarnings = FALSE)
+   objectMeta <- glue::glue(path, "/metadata"); dir.create(objectMeta, showWarnings = FALSE)
+   
+   # Move flats into the flats folder
+   #TODO: with mono, there are about 200 flats per object and this copy is a significant bottleneck
+   # see if I can leverage some system command
+   flatfiles <- list.files(path, pattern = "FLAT", full.names = TRUE)
+   returnStatus = sapply(flatfiles, function(x) file.copy(from = x, to = glue::glue(path, "/flats"), overwrite = T))
+   names(returnStatus) <- NULL
+   if (sum(returnStatus) == length(flatfiles)) {
+     sapply(flatfiles, file.remove)
+   }
+   
+   # grab some info from the file
+   # Figure out how many image loops I need
+   # i.e. if I have two filters, two sets of flats
+   # I need this metric for later
+   temp <- metadata %>%
+     distinct(CameraTargetTemp) %>%
+     pull() %>%
+     as.character()
+   gain <- metadata %>%
+     distinct(Gain) %>%
+     as.character()
+   duration <- metadata %>%
+     distinct(Duration) %>%
+     pull()
+   filter <- metadata %>%
+     distinct(FilterName) %>%
+     pull()
+   imageCombo <- data.frame(temp, gain, duration, filter) # one row per filter
+   
+   
+   # Flag the fit files that need individual review
+   for (i in 1:nrow(imageCombo)) {
+     df <- filter(metadata, FilterName == imageCombo$filter[i])
+     
+     
+     measures <- c("DetectedStars", "HFR", "FWHM", "Eccentricity", "GuidingRMSArcSec")
+     metrics <- lapply(measures, function(x) {
+       sd(df[[x]], na.rm = TRUE)
+     })
+     names(metrics) <- c("stars", "HFR", "FWHM", "roundness", "guiding")
+     
+     # Flag files 
+     df <- df %>%
+       mutate(LowStars = ifelse(DetectedStars < mean(DetectedStars, na.rm = TRUE) - 2 * metrics$stars, 1, 0)) %>%
+       mutate(HighHFR = ifelse(HFR > mean(HFR, na.rm = TRUE) + 2 * metrics$HFR, 1, 0)) %>%
+       mutate(HighFWHM = ifelse(FWHM > mean(FWHM, na.rm = TRUE) + 2 * metrics$FWHM, 1, 0)) %>%
+       mutate(notRound = ifelse(Eccentricity > 0.6, 1, 0)) %>%
+       mutate(badGuiding = ifelse(GuidingRMSArcSec > 1, 1, 0)) %>%
+       mutate(Exclusion = ifelse(LowStars == 1, 1, ifelse(
+         HighHFR == 1, 2, ifelse(HighFWHM == 1, 3, ifelse(
+           notRound == 1, 4, ifelse(
+             badGuiding == 1, 5, 99)))))) %>%
+       mutate(Exclusion = factor(Exclusion, c(1:5, 99), c("Low star count", ">HFR", ">FWHM", 
+                                                          "Eccentricity > 0.6", "Poor Guiding", ""))) %>%
+       mutate(flag = ifelse(Exclusion == "", 0 , 1))
+ 
+ 
+     # Move flagged subs to a directory for individual review
+     flaggedSubs <- df %>%  
+       filter(flag == 1) %>%
+       select(FilePath, FilterName, DetectedStars, HFR, HFRStDev, FWHM, Eccentricity, GuidingRMSArcSec, Exclusion)
+     
+     lapply(flaggedSubs$FilePath, function(x) {
+       if (file.exists(x)) file.copy(x, glue::glue("{path}/checkFits"))
+       if (file.exists(x)) file.remove(x)
+     })
+     
+     # Generate summary report
+     df2 <- df %>%
+       mutate(flag = factor(flag, 0:1, c("Keep", "Flagged"))) %>%
+       group_by(flag, FilterName, Exclusion) %>%
+       summarize(Total_Subs = n(),
+                 Stars =  mean(DetectedStars),
+                 HFR = mean(HFR),
+                 FWHM = mean(FWHM),
+                 Eccentricity = mean(Eccentricity),
+                 Guiding = mean(GuidingRMSArcSec),
+                 TotalMinutes = sum(Duration) / 60,
+                 TotalHours = TotalMinutes / 60)
+                 
+     
+     formatVars <- c("HFR", "FWHM", "Eccentricity", "Guiding", "TotalMinutes", "TotalHours")
+     df2[,formatVars] <- lapply(df2[,formatVars], function(x) {
+       format(round(x, 3), nsmall = 3)
+     })
+     df2$Stars <- floor(df2$Stars)
+     
+     openxlsx::write.xlsx(df2, glue::glue("{objectMeta}/{basename(myObject)}.xlsx"))
+     readr::write_csv(df2, glue::glue("{objectMeta}/{basename(myObject)}.csv"))
+     
+ 
+   }
+   
+   # Copy over my darks
+   # Matches the dark to the temp/gain/duration
+   # Also gets a matched master bias to stack with the flats
+   for (i in 1:nrow(imageCombo)) {
+     getDarks(
+       temp = imageCombo$temp[i],
+       gain = imageCombo$gain[i],
+       duration = imageCombo$duration[i],
+       copyto = path
+     )
+   }
+   
+   # Process my flats
+   # This creates a bat file that calls PixInsight
+   wbppFlats(objectFlats)
+   
+   
+ }
> 
> wbppFlats <- function(objectFlats) {
+   
+   exe <- '"C:\\Program Files\\PixInsight\\bin\\PixInsight.exe"  -n --automation-mode -r='
+   
+   js1 <- '"C:\\Program Files\\PixInsight\\src\\scripts\\WeightedBatchPreprocessing\\WeightedBatchPreprocessing.js,automationMode=true,outputDirectory='
+   
+   outputdir <- objectFlats
+   
+   dir <- glue::glue(objectFlats, '"')
+   
+   js2 <- '--force-exit'
+   
+   foo <- glue::glue("{exe}{js1}{outputdir},dir={dir} {js2}")
+ 
+   wbpp <- file("C:/users/bcart/Astronomy/astro-tools/postprocessing/wbpp.bat", "a")
+   write(foo, wbpp, append = TRUE)
+   close(wbpp)
+   
+ }
> 
> testit <- function(x) {
+   p1 <- proc.time()
+   Sys.sleep(x)
+   proc.time() - p1
+ }
> 
> countFlats <- function(objectFlats) {
+   
+   nFlats <-list.files(objectFlats, pattern = "fits")
+   L <- nFlats[grep("L", nFlats)]
+   R <- nFlats[grep("R", nFlats)]
+   G <- nFlats[grep("G", nFlats)]
+   B <- nFlats[grep("B", nFlats)]
+   H <- nFlats[grep("H", nFlats)]
+   S <- nFlats[grep("S", nFlats)]
+   O <- nFlats[grep("O", nFlats)]
+   
+ 
+   
+   L <- ifelse(length(L) > 0, 1, 0)
+   R <- ifelse(length(R) > 0, 1, 0)
+   G <- ifelse(length(G) > 0, 1, 0)
+   B <- ifelse(length(B) > 0, 1, 0)
+   H <- ifelse(length(H) > 0, 1, 0)
+   S <- ifelse(length(S) > 0, 1, 0)
+   O <- ifelse(length(O) > 0, 1, 0)
+   
+   sum(L, R, G, B, H, S, O)
+ 
+   
+ }
> 
> 
> 
> 
> # Directories -------------------------------------------------------------
> 
> src <- file.path("C:/users/bcart/Astronomy/astro-tools/postprocessing")
> 
> camera <- "c:/users/bcart/astronomy/ASI2600MM/ES127"
> 
> darks <- file.path(camera, "../Dark Library/") 
> 
> objects <- list.dirs(camera, recursive = FALSE, full.names = TRUE) %>%
+   list.dirs(recursive = FALSE, full.names = TRUE)
> 
> 
> objects %>%  lapply(processObjects)
Rows: 95 Columns: 34
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr   (4): FilePath, FilterName, Binning, PierSide
dbl  (28): ExposureNumber, Duration, CameraTemp, CameraTargetTemp, Gain, Off...
dttm  (2): ExposureStart, ExposureStartUTC

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
`summarise()` has grouped output by 'flag', 'FilterName'. You can override
using the `.groups` argument.
`summarise()` has grouped output by 'flag', 'FilterName'. You can override
using the `.groups` argument.
`summarise()` has grouped output by 'flag', 'FilterName'. You can override
using the `.groups` argument.
`summarise()` has grouped output by 'flag', 'FilterName'. You can override
using the `.groups` argument.
Rows: 74 Columns: 34
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
chr   (4): FilePath, FilterName, Binning, PierSide
dbl  (28): ExposureNumber, Duration, CameraTemp, CameraTargetTemp, Gain, Off...
dttm  (2): ExposureStart, ExposureStartUTC

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
`summarise()` has grouped output by 'flag', 'FilterName'. You can override
using the `.groups` argument.
`summarise()` has grouped output by 'flag', 'FilterName'. You can override
using the `.groups` argument.
`summarise()` has grouped output by 'flag', 'FilterName'. You can override
using the `.groups` argument.
[[1]]
[1] 0

[[2]]
[1] 0

> 
> 
> 
>   
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> proc.time()
   user  system elapsed 
   4.79   25.21  169.46 
